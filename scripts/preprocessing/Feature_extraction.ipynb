{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TP8d_36z0LP8",
        "outputId": "ac8fa35f-1dd7-4294-cbb3-f5ae9803c3c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting better_profanity\n",
            "  Downloading better_profanity-0.7.0-py3-none-any.whl (46 kB)\n",
            "\u001b[?25l\r\u001b[K     |███████                         | 10 kB 19.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 20 kB 24.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 30 kB 28.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 40 kB 20.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 46 kB 2.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: better-profanity\n",
            "Successfully installed better-profanity-0.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip install better_profanity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "AlXzFnI_zf5l"
      },
      "outputs": [],
      "source": [
        "#libreria para medir el profanity.\n",
        "\n",
        "from better_profanity import profanity\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk.tokenize import WordPunctTokenizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "QCxfwldr0WCs"
      },
      "outputs": [],
      "source": [
        "def load_emolex(path = \"emolex\"):\n",
        "  \"\"\"\n",
        "  Método para cargar el emolex, indica la emoción de una palabra (anger, fear, anticipation, trust, surprise, sadness, joy, and disgust)\n",
        "  y 2 sentimientos (positive. negative)\n",
        "  \"\"\"\n",
        "\n",
        " #Realizar unzip al archivo emolex\n",
        "  !unzip emolex.zip\n",
        "  vocab = {}\n",
        "  base_path = path\n",
        "\n",
        "\n",
        "  #Cargar los emolex en un diccionario\n",
        "  for lexicon in os.listdir(base_path):\n",
        "    with open(os.path.join(base_path, lexicon)) as f:\n",
        "      vocab[lexicon.split(\".\")[0]] = f.read().split(\"\\n\")\n",
        "\n",
        "\n",
        "  #regresar el vocab con los emolex\n",
        "  return vocab\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "98nZzvCIUh-d"
      },
      "outputs": [],
      "source": [
        "def count_profanity_sentences(doc):\n",
        "  \"\"\"\n",
        "  Método para identificar la cantidad de groserias dentro de un texto\n",
        "  \"\"\"\n",
        "  doc_prof = [profanity.censor(word) for word in str(doc).split(\" \")]\n",
        "  doc_prof = [word for word in doc_prof if \"*\" in word]\n",
        "\n",
        "  return len(doc_prof)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "Q1sA38dHq9s6"
      },
      "outputs": [],
      "source": [
        "def get_profanity_ratio(df, col):\n",
        "    \"\"\" \n",
        "    df -> dataFrame\n",
        "    col -> Columna con las lyrics\n",
        "    \"\"\"\n",
        "\n",
        "    df[\"Prof_Count\"] = df[col].apply(count_profanity_sentences)\n",
        "    df[\"Words\"]      = df[col].str.split(\" \").apply(len)\n",
        "    df[\"Profanity Ratio\"] = (df[\"Prof_Count\"] / df[\"Words\"]) * 100\n",
        "    df.drop(columns = [\"Prof_Count\", \"Words\"], inplace = True)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "kJoXdLS43_sq"
      },
      "outputs": [],
      "source": [
        "# Función auxiliar para estimar la distribución de emociones en un texto\n",
        "def emotion_count(text, vocab):\n",
        "  \"\"\"\n",
        "  Función para estimar la distribuciones de emociones del emolex\n",
        "  \"\"\"\n",
        "  words = WordPunctTokenizer().tokenize(text) #separamos palabras\n",
        "  counts = {i: 0 for i in list(vocab.keys())}\n",
        "  for word in words:\n",
        "      for emo in vocab:\n",
        "          if word in vocab[emo]:\n",
        "              counts[emo] += 1\n",
        "  return counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "4M2-NVON4PZG"
      },
      "outputs": [],
      "source": [
        "# Consolidamos los sentimientos encontrados en cada artista \n",
        "\n",
        "songs_sentiment = []\n",
        "\n",
        "for i in np.unique(songs_df['artist']):\n",
        "  songs_sentiment.append(emotion_count(\" \".join(np.array(songs_df['lyric'])[songs_df['artist']==i]), vocab))\n",
        "\n",
        "artist_sentiment = pd.DataFrame(songs_sentiment)\n",
        "artist_sentiment.set_index(np.unique(songs_df['artist']), inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "8FlZNkPYYTTl"
      },
      "outputs": [],
      "source": [
        "def emolex_df(artist, corpus, vocab):\n",
        "  \"\"\"\n",
        "  Dataframe con el % de emociones que se tiene para cada artista, cada columna es un sentimiento\n",
        "\n",
        "  artist -> listado de artistas\n",
        "  corpus -> lyrics por artistas\n",
        "  vocab -> vocabulario con el emolex de palabras y su sentimiento asociado\n",
        "  \"\"\"\n",
        "\n",
        "  #Lista vacia para agregar el conteo de emolexs\n",
        "  artist_sentiment =[]\n",
        "\n",
        "  for i in np.unique(artist):\n",
        "    artist_sentiment.append(emotion_count(\" \".join(np.array(corpus)[artist==i]), vocab))\n",
        "\n",
        "  #Se crea un DataFrame con los valores y se dejan en terminos porcentuales sobre el total de apariciones por artista (normalización)\n",
        "  artist_sentiment = pd.DataFrame(artist_sentiment)\n",
        "  artist_sentiment.set_index(np.unique(artist), inplace=True)\n",
        "\n",
        "  #Dejar en terminos porcentuales el conteo de sentimientos.\n",
        "  artist_sentiment['Total'] = artist_sentiment.sum(axis=1)\n",
        "\n",
        "  #iterar en cada columna para obtener el % sobre el total\n",
        "  for column in artist_sentiment.columns:\n",
        "    artist_sentiment[f\"{column}\"] =  (artist_sentiment[f\"{column}\"] / artist_sentiment['Total'] * 100 )\n",
        "    \n",
        "  artist_sentiment.drop(['Total'],axis=1, inplace= True)\n",
        "\n",
        "  return artist_sentiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eiGaGfIUTn2g",
        "outputId": "32318004-dcbb-4b88-e8f2-633b6f7d0da6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  emolex.zip\n",
            "replace emolex/sadness.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: emolex/sadness.txt      \n",
            "  inflating: emolex/negative.txt     \n",
            "  inflating: emolex/trust.txt        \n",
            "  inflating: emolex/surprise.txt     \n",
            "  inflating: emolex/fear.txt         \n",
            "  inflating: emolex/anticipation.txt  \n",
            "  inflating: emolex/disgust.txt      \n",
            "  inflating: emolex/positive.txt     \n",
            "  inflating: emolex/joy.txt          \n",
            "  inflating: emolex/anger.txt        \n"
          ]
        }
      ],
      "source": [
        "vocab = load_emolex()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "xLx8P0r1ADZz"
      },
      "outputs": [],
      "source": [
        "artist_songs_df = pd.read_csv(\"artist_corpus.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "HQq4Ril8AKlZ"
      },
      "outputs": [],
      "source": [
        "artist_songs_df = artist_songs_df[['artist','lyric']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "A-9lociHrIgY"
      },
      "outputs": [],
      "source": [
        "get_profanity_ratio(artist_songs_df, \"lyric\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "xKboRnN6cXQG"
      },
      "outputs": [],
      "source": [
        "df_artist_emolex = emolex_df(artist_songs_df['artist'], artist_songs_df['lyric'], vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "pi1KdP0-ejcx"
      },
      "outputs": [],
      "source": [
        "df_artist_emolex.to_csv(\"df_features_emolex.csv\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Feature_extraction.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
