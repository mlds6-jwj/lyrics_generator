{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Implementation_LSTM.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "LvC917aDZmiw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6409aa5-ae30-4da3-8e17-017346a18475"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    %tensorflow_version 2.x\n",
        "    %load_ext tensorboard\n",
        "except Exception:\n",
        "    pass\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os, random\n",
        "import re\n",
        "\n",
        "tf.random.set_seed(123)\n",
        "np.random.seed(123)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_corpus(path):\n",
        "  \"\"\"\n",
        "  path: Path relativo a este script\n",
        "  Esta función carga el corpus para su procesamiento y lectura en la red neuronal\n",
        "  \"\"\"\n",
        "  with open(path) as f:\n",
        "    corpus = f.readlines()\n",
        "    corpus = ' '.join(corpus)\n",
        "  return corpus"
      ],
      "metadata": {
        "id": "s9fX0wRQayml"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vectorized_text(corpus):\n",
        "  \"\"\"\n",
        "  corpus: str, texto completo a usar para entrenar el modelo.\n",
        "  Función que recibe un texto y lo devuelve en una representación númerica.\n",
        "  \"\"\"\n",
        "  \n",
        "  #Vocabulario, caracteres unicos que aparecen en el corpus\n",
        "  vocab = sorted(np.unique(list(set(corpus))))\n",
        "  #Asignar un valor numerico a cada caracter\n",
        "  char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "  #letra asignada al vocab\n",
        "  idx2char = np.array(vocab)\n",
        "\n",
        "  text_as_int = np.array([char2idx[c] for c in corpus])\n",
        "\n",
        "  return text_as_int, idx2char"
      ],
      "metadata": {
        "id": "Ohwh7FiYmGxD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_input_target(chunk):\n",
        "  \"\"\"\n",
        "  Variable objetivo a predecir\n",
        "  \"\"\"\n",
        "  input_text = chunk[:-1]\n",
        "  target_text = chunk[1:]\n",
        "  return input_text, target_text"
      ],
      "metadata": {
        "id": "a-j9PKFOguE_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dataset_preparation(text_as_int, len_corpus, seq_length=100, buffer_size = 10000, batch_size = 64):\n",
        "  \"\"\"\n",
        "  Función que devuelve el numero de ejemplos por epoch y el dataset procesado\n",
        "  \"\"\"\n",
        "  examples_per_epoch = len_corpus // (seq_length + 1) \n",
        "  char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
        "  sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "  dataset = sequences.map(split_input_target).shuffle(buffer_size).batch(batch_size, drop_remainder=True)\n",
        "  return examples_per_epoch, dataset"
      ],
      "metadata": {
        "id": "-Dq9lVZreilk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_test_split(dataset):\n",
        "  \"\"\"\n",
        "  Separación en train y split\n",
        "  \"\"\"\n",
        "  test_dataset = dataset.take(int(len(list(dataset))*0.2))\n",
        "  train_dataset = dataset.skip(int(len(list(dataset))*0.2))\n",
        "  return (test_dataset, train_dataset)"
      ],
      "metadata": {
        "id": "se1k7ymnqVAB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss(labels, logits):\n",
        "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)"
      ],
      "metadata": {
        "id": "5glezHXZiWB4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_definition(vocab, embedding_dim = 256, rnn_units = 1024, buffer_size = 10000, batch_size = 64, recurrent_initializer = 'glorot_uniform', dense_dim = 128, activation = \"relu\", dropout = 0.2):\n",
        "  \"\"\"\n",
        "  Definición del modelo LSTM que incluye una capa de embedding, la capa LSTM, 2 capas densas y un Dropout\n",
        "  \"\"\"\n",
        "  model = tf.keras.Sequential([tf.keras.layers.Embedding(len(vocab), embedding_dim,\n",
        "                                                            batch_input_shape=[batch_size, None]),\n",
        "                                  tf.keras.layers.LSTM(rnn_units,\n",
        "                                                       return_sequences=True, #este argumento hace que el modelo sea many-to-many\n",
        "                                                       stateful=True,\n",
        "                                                       recurrent_initializer = recurrent_initializer),\n",
        "                                  tf.keras.layers.Dense(dense_dim,\n",
        "                                                        activation=\"relu\"),\n",
        "                                  tf.keras.layers.Dropout(dropout),\n",
        "                                  tf.keras.layers.Dense(len(vocab))])\n",
        "  return model"
      ],
      "metadata": {
        "id": "-AubD0X4bTas"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compile_model(model, optimizer, loss, metrics):\n",
        "  \"\"\"\n",
        "  Función para compilar el modelo\n",
        "  \"\"\"\n",
        "  model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
      ],
      "metadata": {
        "id": "bRB-MLu6kM6v"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_model(model, train_dataset, test_dataset, epochs, examples_per_epoch, validation_steps, batch_size=64, saving_path = 'lstm.h5'):\n",
        "  \"\"\"\n",
        "  Función de entrenamiento del modelo\n",
        "  \"\"\"\n",
        "  checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=saving_path,\n",
        "    save_weights_only=True, save_best_only = True)\n",
        "  model.fit(train_dataset.repeat(), validation_data = test_dataset.repeat(), epochs=epochs, callbacks=[checkpoint_callback], \n",
        "                 steps_per_epoch=examples_per_epoch//batch_size, validation_steps = validation_steps)"
      ],
      "metadata": {
        "id": "cSpd338QiejM"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, start_string, vocab, text_len=500, temperature=0.5):\n",
        "\n",
        "    \"\"\"\n",
        "    Función que genera texto de manera automática a partir de predecir el siguiente caracter mas probable\n",
        "    recibe como input el modelo, un texto plano, un vocabulario y una temperatura para ajustar el resultado.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    # vectorizamos el string inicial\n",
        "    char2idx = {u:i for i, u in enumerate(vocab)}\n",
        "    input_eval = [char2idx[s] for s in start_string]\n",
        "    input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "    # Lista para guardar los resultados\n",
        "    text_generated = []\n",
        "\n",
        "    # Reiniciamos los estados del modelo\n",
        "    model.reset_states()\n",
        "    # iteramos para obtener el número de carácteres deseado\n",
        "    for i in range(text_len):\n",
        "        # obtenemos las predicciones\n",
        "        predictions = model(input_eval)\n",
        "        # removemos el eje de los batch\n",
        "        predictions = tf.squeeze(predictions, 0)\n",
        "\n",
        "        # utilizamos la distribución categorica para obtener el siguiente caracter\n",
        "        predictions = predictions / temperature\n",
        "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
        "        # predicted_id es el caracter predicho (este será la entrada en la siguiente iteración)\n",
        "        input_eval = tf.expand_dims([predicted_id], 0)\n",
        "        # agregamos el string correspondiente al id predicho\n",
        "        text_generated.append(idx2char[predicted_id])\n",
        "    return (start_string + ''.join(text_generated))"
      ],
      "metadata": {
        "id": "kdM4xWqI9f5x"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def export_generated_lyrics(path, generated_lyrics):\n",
        "  with open(path, \"w\") as f:\n",
        "    writer = f.write(generated_lyrics)"
      ],
      "metadata": {
        "id": "E8h4rXK9BbeO"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = load_corpus('corpus.txt')"
      ],
      "metadata": {
        "id": "SuGcB3rOnPfZ"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = re.sub(' +', ' ',re.sub(r\"\\xa0|\\u2005|\\u200a|\\u205f|ah|Oh|hey|yeah\", \" \", corpus))"
      ],
      "metadata": {
        "id": "vpem2BHF8SwF"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_as_int, idx2char = vectorized_text(corpus)"
      ],
      "metadata": {
        "id": "1-3cP4Fpnubh"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "examples_per_epoch, dataset =  dataset_preparation(text_as_int = text_as_int, len_corpus = len(corpus))"
      ],
      "metadata": {
        "id": "VKTqVNO4n75y"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset, train_dataset = train_test_split(dataset)"
      ],
      "metadata": {
        "id": "yoqI5cxLq3Oh"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = model_definition(vocab = idx2char)"
      ],
      "metadata": {
        "id": "Jdq-FbiWo6U5"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compile_model(model, optimizer = \"adam\", loss = loss, metrics = 'accuracy')"
      ],
      "metadata": {
        "id": "GxjbZFJmo-_8"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fit_model(model, train_dataset, test_dataset, 1, examples_per_epoch, validation_steps = 48)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXNCYokDpNPs",
        "outputId": "7bfe0685-8a28-4a99-8ced-31088da9d1ce"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "317/317 [==============================] - 71s 196ms/step - loss: 2.4716 - accuracy: 0.3232 - val_loss: 1.8910 - val_accuracy: 0.4443\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_lstm = model_definition(vocab = idx2char, batch_size= 1)"
      ],
      "metadata": {
        "id": "9cNGx7NM6AaJ"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_lstm.load_weights(\"lstm.h5\")"
      ],
      "metadata": {
        "id": "lLwQd4ps7x49"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_lyrics =generate_text(model = model_lstm, start_string= \"This is the story of a man who\", vocab = idx2char, text_len = 1200, temperature = 0.65)"
      ],
      "metadata": {
        "id": "rXa4tGG3-5ui"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(random_lyrics)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxWjO04SDH_S",
        "outputId": "f1376355-2124-4789-b722-1eaefa74190a"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the story of a man who so bridges\n",
            "And drop a hotel brand new\n",
            "Stop this life you're terisa a couple of pain life, pass you, but you're hard to love\n",
            "\n",
            "And I don't know why your world was living in\n",
            "I'll showed you my life\n",
            "I'd like to close my eyes, I'll be there to short the risk\n",
            "Let yourself go, let your mind as a dream won't leave my life to me what you gave me\n",
            "I said, Curound down in the summer plastic feels like a nesplayer\n",
            "So when I rat it all\n",
            "Yes we all along\n",
            "The father of falling apart\n",
            "I won't let you sleep\n",
            "I can't do this anymore\n",
            "What are you waiting for\n",
            "Aren't you tired of all of the violence inside of you\n",
            "Handsome home\n",
            "Home, one last time\n",
            "\n",
            "I need something to love, you can run with me\n",
            "The moment you forgive me\n",
            "No one understand\n",
            "Girl, you and I will die unbelievers\n",
            "Bound to the top\n",
            "You're gonna stand my grip, but my shadow on me\n",
            "The sky is a neighborhood \n",
            " \n",
            " \n",
            " \n",
            " \n",
            " Show me the dirt pile and I will give you my fan you're all worth it\n",
            "For you to find something to be patient\n",
            "Time is of the essence\n",
            "Girl, you gotta be patient\n",
            "\n",
            "If you could see it, if you could see it through my eyes\n",
            "Why are we so different\n",
            "Want you to feel it, want you to know what it was like\n",
            "Then maybe you'll understand\n",
            "That someone sa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "export_generated_lyrics(\"generated_lyrics.txt\", random_lyrics)"
      ],
      "metadata": {
        "id": "4XQX15CHCoIn"
      },
      "execution_count": 76,
      "outputs": []
    }
  ]
}